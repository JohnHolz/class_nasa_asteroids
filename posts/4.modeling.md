<h1 style="text-align: center;">Modelagem</h1>

Aqui vamos tentar escolher quais modelos manteremos, mais de 2 fica dificil de mante e entender em quem acreditar, muita gente falando na cabeça e já tenho muitas vozes nela, então vamos simplificar.

**Qual nosso principal objetivo?**

- Identificar todos asteroides potencialmente perigosos;
- Não deixar a nossa querida raça humana ser pega desprevinida com qualquer asteoide colidindo com nosso planeta e destruindo toda a vida.

**Catapimbas, Ora bolas, mas o que isso significa?**

- Sem erros tipo 1;
- Vamos abusar no erro tipo 2.

Não vamos deixar os modelos predizerem o classe, vamos pedir que retorne probabilidades e então avaliar nosso threashold, que vamos reduzir até conseguirmos minimizar o erro tipo 1, o que automaticamente pode inflacionar o tipo 2.

Divisão do dataset será apenas em 2 partes, treino e teste, deixaremos a validação para o próximo artigo. Variaremos o scaler, entre Standard e o MinMax, e manteremos o que estiver perfomando melhor.

**Vantagens de utilizar scaling no problema**

1. Dependendo do modelo treina mais rapido;
2. Resposta não precisar de scaling;
3. Não precisar explicar parametros reescalados ou transformar de volta em algum momento.

**Primeiros passos no codigo**
Primeiro precisamos dividir o dataset, depois aplicar o scaler, pois o scaler precisa primeiro ver o subset de treino, depois escalar o teste.

        x,y = get_x_y()
        x_train,x_test,y_train,y_test = train_test_split(x,y,
                                                        test_size=0.3,
                                                        stratify=y,
                                                        random_state=42
                                                        )
        standard = StandardScaler()
        x_train = standard.fit_transform(x_train)
        x_test = standard.transform(x_test)

Essa função get_x_y pode ser vista em modules no repositorio. Ela retorna já com as dummies para não precisarmos ficar preocupados com isso nos notebooks. Para o codigo ficar mais limpo possivel.

### Benchmark Models

Para benchmark comecei com modelos simples, decision tree e knn, só lembrei que knn iria demorar pra sempre com esse dataset depois de começar a rodar porem esperei.  
Ambos performaram excessivamente mal, a humanindade estaria perdida.  
Mesmo reduzindo a probabilidade de aceite pra 0.05 o modelo performou dessa maneira. Como introduzimos, queremos a posição (1,0) seja minima possivel, com foco em chegar em 0, então esse é um mal exemplo.  
**Precisão da classe: 520/620**

                N     Y
        N  277984  1097
        Y     100   520

Vamos agora focar em minimizar esse valor, vamos abusar no erro tipo 2 mas não a ponto dele ficar 50% maior do que do knn.

Definidos os requisitos:

1. Precisão da classe mais próximo de 100% possivel;
2. Erro tipo 2 menor que 1500.

### First good models

Não vou colocar todas interações de todos modelos e nem todos que testei, 3 bons que cheguei a bons resultados para compararmos, foram Adaboost e RandomForest e o a multilayer neuralnet with tensorflow.

        rf = RandomForestClassifier(n_estimators=80)
        ada = AdaBoostClassifier()
        tf_model = tf_model()

Para chegar no modelo de redes passamos pela seguinte sequencia de alterações até estabilizarmos na atual:

| loss | opt  | ll act  | metric    | dropout    | layers   | data      | epoch | batch    |
| ---- | ---- | ------- | --------- | ---------- | -------- | --------- | ----- | -------- |
| BC   | rms  | sigmoid | 143/620   | True       | 2 layers | no sigmas | ~30   | no notes |
| mse  | adam | sigmoid | 134/620   | True       | 2 layers | no sigmas | ~30   | no notes |
| BC   | adam | sigmoid | 49/620    | True       | 2 layers | no sigmas | ~30   | no notes |
| BC   | adam | sigmoid | 58-12/620 | True       | 2 layers | no sigmas | ~30   | no notes |
| BC   | adam | sigmoid | 78-54/620 | no dropout | 1 layer  | no sigmas | ~30   | no notes |
| BC   | adam | sigmoid | 26-5/620  | no dropout | 2 layers | no sigmas | ~30   | no notes |
| BC   | adam | sigmoid | 48-18/620 | no dropout | 3 layers | no sigmas | ~30   | no notes |
| BC   | adam | sigmoid | 40-15/620 | no dropout | 2 layers | full data | ~30   | no notes |
| BC   | adam | sigmoid | 18-9/620  | no dropout | 3 layers | full data | ~30   | no notes |
| BC   | adam | tanh    | 120/620   | no dropout | 3 layers | full data | ~30   | no notes |
| BC   | adam | sigmoid | 5-1/620   | no dropout | 3 layers | full data | 20    | 128      |
| BC   | adam | sigmoid | 5-1/620   | no dropout | 3 layers | full data | 40    | 128      |
| BC   | adam | sigmoid | 5-1/620   | no dropout | 3 layers | full data | 40    | 64       |

        {
        3 layer 10x16x8x1
        loss: Binary crossentropy
        opt:Adam
        Activations: Relu
        Last Layer: Sigmoid
        Epochs:~50
        }

#### Próximo artigo: [Artigo 5](Artigo 5)
